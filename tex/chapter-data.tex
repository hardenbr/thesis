\chapter{Big Data\label{ch:data}}

The LHC delivers $pp$ collisions at a very high rate, much higher than CMS can read out or store
offline. From all these collisions, CMS selects a subset of events many order of magnitudes smaller
which are the most relevant for the physics processes of interest. This task is accomplished
through the trigger system, which is discussed in Section~\ref{sec:trigger} both in general and
in the context of this analysis. The events selected by the trigger system compose the datasets
used by all CMS analyses. The worldwide computing grid for storage and processing of both datasets
and simulation samples is disussed in Section~\ref{sec:storage}. Finally, the simulation samples
employed by this analysis are discussed in Section~\ref{sec:sim}.


\section{The Trigger System\label{sec:trigger}}

The gap in time between successive bunch crossings by the LHC is 25 ns, which is equivalent to
a frequency of 40 MHz. This large rate is reduced by selecting only the most interesting events
in a two-level trigger system. The first level, Level 1 (L1), is hardward-based and reduceds the
total event rate from 40 MHz to 100 kHz~\cite{Bayatyan:706847}, whereas the second level,
the High Level Trigger (HLT) is software-based and reduces the total event rate from 100 kHz to
100 Hz~\cite{Virdee:1043242}. From here, the events are processed further and stored
for the physics analyses.

The L1 trigger attempts to identify basic physics objects based on coarse energy deposits in
ECAL or HCAL or
based on collections of hits in muon chambers. By scanning the energy deposited in the calorimeters,
quantities derived from the sum of energy deposited, such as the missing transverse energy $\met$.
The Level 1 global trigger (GT) combines these object candidates and derived quantities in order
to select events to pass the the HLT with a processing time of $3 \mu$s.
Up to 128 separate trigger paths may be supported.

The HLT is able to access more information than the L1 trigger, and in doing so it can provide
a better description of the event. At the HLT level, tracker information is used in conjunction with
the full granularity of ECAL and HCAL. Information at this level is based on the presence of one or
more candidate objects satisfying requirements based on their transverse momentum or energy and relative
or absolute positions in the detector. With this added complexity and fewer events to process,
the average processing time is 40 ms.

\subsection{The Trigger for $\ggbb$}

In the search for the $\ggbb$ final state, this analysis can be viewed as an extension of the
SM $\Hgg$ search~\cite{HggCMSpaper}. The excellent diphoton mass
resolution is the principle driver in the sensitivity since it allows for low background contamination
in the signal region, as will be shown in Chapter~\ref{ch:results}.
Therefore, the trigger strategy centers on the ability to find two high-quality photon candidates.

During 2012 data taking, the LHC luminosity increased over time, and the triggers at both L1 and HLT
had their thresholds increased in order to keep the event rates within the limits of the two levels.
The requirement at L1 is for two $e/\gamma$ candidates with $E_{\rm T}$ requirements of 13 (7) GeV
for the lead (sublead) candidate or for one $e/\gamma$ candidate with an $E_{\rm T}$ requirement of
22 GeV.

At HLT events are selected through diphoton triggers with asymmetric $E_{\rm T}$ thresholds
and complementary photon selections. One trigger selection requires a loose calorimetric
identification based on the shape of the electromagnetic shower and loose isolation requirements
on the photon candidates, while the other requires that the photon electromagnetic shower
is primarily concentrated in a three-by-three crystals super-cluster.
The trigger thresholds on the photon $E_{\rm T}$ are 26 (18) GeV and 36 (22) GeV on the leading
(subleading) photon, depending on the acquisition period of LHC data taking in 2012.
The path with the 26 (18) GeV thresholds is initiated by the L1 path with 13 (7) GeV thresholds, while
the path with 36 (22) GeV thresholds is initiated by the L1 path with a single 22 GeV threshold.

In addition to keeping the trigger rate within its limits, it is also neccessary to set thresholds
low enough such that the selection of signal events remains as high as possible. This trigger efficiency
is studied on Monte Carlo (MC) signal samples as well as on $Z\rightarrow e^+ e^-$ data.
For the study on MC, the efficiency is above 99.5\% for all conditions of 2012 data taking.

Figures~\ref{fig:ZeeTriggerPt} and \ref{fig:ZeeTriggerNvtx}
show how the trigger efficiency varies on data with respect to the
candidate photon $p_{\rm T}$ and the number of primary vertices in the event
using the tag and probe technique. To account for differences
between the shower shape between photons and electrons, the data sample was reweighted to match the
shower shapes. Within uncertainties, the trigger efficiency is higher than 99\% for the 2012 data.

\begin{figure}[ht]
 \begin{center}
    \includegraphics[width=0.60\textwidth]{figures/data/turnon_pt.pdf}
      \end{center}
\caption{Efficiency of the trigger selection as a function of the photon candidate transverse
momentum measured in $Z\rightarrow e^+ e^-$ events~\cite{HggCMSpaper}.}
\label{fig:ZeeTriggerPt}
\end{figure}

\begin{figure}[ht]
 \begin{center}
    \includegraphics[width=0.60\textwidth]{figures/data/turnon_nvtx.pdf}
      \end{center}
\caption{Efficiency of the trigger selection as a function of the number of primary vertex in the event
measured in $Z\rightarrow e^+ e^-$ events~\cite{HggCMSpaper}.}
\label{fig:ZeeTriggerNvtx}
\end{figure}


\section{Data Storage Worldwide\label{sec:storage}}

All the data from the LHC and its experiments, including CMS, is processed, stored, and analyzed
in a distributed global collaboration of computing centers~\cite{Eck:840543}. The Worldwide
LHC Computing Grid (WLCG) is the world's largest computing grid, composing of over 170 centers
arranged in a tier structure. Part of this tier structure is shown in Figure~\ref{fig:cerncomputing}

\begin{figure}[ht]
 \begin{center}
    \includegraphics[width=0.70\textwidth]{figures/data/CCApr13-Tiers0-1-2_PNG-file.pdf}
      \end{center}
\caption{A schematic of the WLCG detailing the locations of the Tier-1 sites~\cite{cern:computing}.}
\label{fig:cerncomputing}
\end{figure}

Tier 0 is the CERN Data Center, through which all LHC data passes for initial processing and
reconstruction. The raw and processed data from Tier 0 is pushed to one of the 13 Tier 1 sites, where
later reprocessing and storage can be done. From here, the Tier 1 sites push the reconstructed
datasets to Tier 2 sites for storage and processing by analysts. This system handles the approximately
30 Petabytes of data generated per year by the LHC experiments in addition to the large amount of
MC samples generated and stored.

\section{Simulation Samples\label{sec:sim}}

%include more theory details on radion, graviton, mssm used in the sample generation

MC simulation samples are employed to study signal and background processes in more detail
than would be offered by data alone. In a search for some new signal process, there is a trade-off
between optimizing an analysis for one particular new physics scenerio and the ability to
generalize a result to other signal processes. This analysis generally searches for a double Higgs final
state by optimizing strategies separately between the resonant and nonresonant production mechanisms.
The signal MC samples are discussed in Subsection~\ref{subsec:sig_samples}.
In addition, good agreement between data
and background MC serves as a validation that the major backgrounds are understood and that
the data is behaving as expected. The background MC samples are discussed in
Subsection~\ref{subsec:bkg_samples}.

\subsection{Signal Simulation\label{subsec:sig_samples}}

The resonant search is focused on a new resonance from a massive particle $X$ with mass $m_X$ between
260 GeV and 1.1 TeV. The lower bound is set by twice the Higgs mass since the search looks for decays
$X\rightarrow HH$. The upper bound is set by the ability to reconstruct the $\ggbb$ final state: for
very high resonance hypotheses, the decay production become very boosted, causing photons of the
$\Hgg$ decay fail being properly identified and causing the jets of the $\Hbb$ decay to overlap.
These reconstruction methods are discussed in Chapter~\ref{ch:objects}. For the nonresonant
search, there is no concern for the final state being too boosted.

In the resonant search, the benchmark model is that of the Radion, which is simulated with
MadGraph5~\cite{Madgraph_Alwall:2011uj} and hadronized with Pythia6~\cite{Pythia6-0}. The events are
generated from the gluon-fusion production of an on-shell Radion where the decay width of the radion
is 10 MeV, much less than the experimental resolution of the final state products. There are roughly
20k events generated per mass point, with twice the amount at three points.
This is summarized in Table~\ref{table:radion_mc} with the corresponding cross sections given in terms
of parameters described in Chapter~\ref{ch:intro}.

\begin{table}[ht]
  \centering
  \renewcommand{\arraystretch}{1.4}
  \caption{Radion simulation samples and their corresponding cross sections.}
  \input{tables/radion_mc}
  \label{table:radion_mc}
\end{table}

In order to verify the model-independence of the result, two additional signal samples are generated.
The spin-2 Graviton is considered as the angular distribution of the final state differs from a
spin-0 scenerio. However, due to the expected sensitivity of the analysis, as shown in
Chapter~\ref{ch:results}, the analysis is not expected to be able to differentiate between
these two scenerios. This will be explicitely checked in Chapter~\ref{ch:results} as well.
These samples were generated with a decay width of 1 GeV and 10 GeV,
which also allow for the accessment of the
dependence of the width-dependence on the final result. The production mechanism is through
gluon fusion, generated with MadGraph5 and hadronized with Pythia6. The sample generation
is summarized in Table~\ref{table:graviton_mc} with corresponding cross sections given in terms of
parameters described in Chapter~\ref{ch:intro}. Here, the RS1 KK-graviton refers to a scenerio
where $c_i = 1$ in Equation~\ref{eq:wed_lagrangian}, whereas the bulk KK-graviton refers to a scenerio
in which the couplings between light quarks and the graviton are suppressed, leading to the
production cross section of the bulk KK-graviton to be lowered by a factor of 0.02. The cross sections
are given in Table~\ref{table:graviton_xsec}.

\begin{table}[ht]
  \centering
  \renewcommand{\arraystretch}{1.4}
  \caption{Graviton simulation samples.}
  \input{tables/graviton_mc}
  \label{table:graviton_mc}
\end{table}

\begin{table}[ht]
  \centering
  \renewcommand{\arraystretch}{1.4}
  \caption{Graviton cross sections. Note that there is assumes the maximal
braching ratio of 25\% for the KK-graviton to two Higgs for all masses. The cross section is the
same for the 1 GeV and 10 GeV width because the specific values of fermion localization leave some
freedom in the partial width of the KK-graviton to two top quarks~\cite{Agashe:2007zd}.}
  \input{tables/graviton_xsec}
  \label{table:graviton_xsec}
\end{table}

A second alternative signal scenerio to the Radion benchmark is the spin-0 heavy neutral Higgs from
the MSSM. These samples are generated and showered with Pythia6. For this scenerio, only low-mass
resonance hyptheses are generated since, once the heavy Higgs mass rises above twice that of the top
mass, it will overwhelming decay through that channel. The sample generation for the MSSM heavy
Higgs is summarized in Table~\ref{table:mssm_mc}.

\begin{table}[ht]
  \centering
  \renewcommand{\arraystretch}{1.4}
  \caption{MSSM heavy Higgs simulation samples.}
  \input{tables/mssm_mc}
  \label{table:mssm_mc}
\end{table}

In the search for nonresonant HH production, the three parameters $\kapl$, $\kapt$, and $\ctwo$
may be varied as discussed in Subsection~\ref{subsec:nonres_th}. These samples are generated
with MadGraph5 using suitable ranges for the parameters about their corresponding SM values. The
values considered for $\kapl$ are -20, -15, -10, 0, 1, 2, 3, 5, 10, 15, and 20; for $\kapt$ 0.75, 1, and 1.25; and for $\ctwo$ -3, -2, 0, 2, and 3.
With these values, 124 scenerios are generated, each having about 20k events.

\subsection{Background Simulation\label{subsec:bkg_samples}}

The backgrounds processes for the search of double Higgs production are divided in resonant and
nonresonant groups. The resonant backgrounds consist of SM Higgs production with $\Hgg$, meaning
that for the diphoton mass, one of the most powerful discriminators between signal and background,
these processes have the exact same distribution as the signal being sought. The nonresonant backgrounds
consist of SM processes which have final state objects reconstructed as $\ggbb$.

For the resonant background, six (five) processes are considered for the resonant (nonresonant) search.
Four of the processes are SM single Higgs production with the $\Hgg$ decay: gluon-gluon fusion, vector
boson fusion, associated production with a vector boson, and associated production with a pair of
t-quarks, as shown in Figure~\ref{fig:higgsprod}. Gluon-gluon fusion mimicks the final state when two
jets are reconstructed from initial state or final state radionation or from the underlying event.
The other production mechanisms produce two jets directly,
noting that in associated production with a vector boson the vector boson can decay to two jets, and
that in associated production with a pair of t-quarks each t-quarks always decays to $bW$.
These four processes were generated and hadronized with Pythia6.
In addition, a fifth mechanism, associated production with a pair of b-quarks, is considered for
both searches and was generated with MadGraph5.
For the resonant search, a final resonant background is considered, that of the
SM double Higgs production (i.e. the signal process for the nonresonant search).
This is summarized in Table~\ref{table:smhiggs_mc}, and its corresponding effect on the analysis
sensitivity is given in Chapter~\ref{chapter:results}.

\begin{table}[ht]
  \centering
  \renewcommand{\arraystretch}{1.4}
  \caption{Resonant background simulation samples and their corresponding cross sections.}
  \input{tables/smhiggs_mc}
  \label{table:smhiggs_mc}
\end{table}

